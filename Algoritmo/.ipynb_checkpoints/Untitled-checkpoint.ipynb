{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8f5795-9179-4a74-b43c-f12ce6db238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# SEÇÃO 1: IMPORTAÇÃO DAS BIBLIOTECAS\n",
    "# ==============================================================================\n",
    "# Importando pandas para manipulação de dados\n",
    "import pandas as pd\n",
    "# Importando RandomForestRegressor, o nosso modelo de machine learning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Importando as métricas para avaliar a acurácia do modelo\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# Importando numpy para operações matemáticas, como a raiz quadrada (sqrt)\n",
    "import numpy as np\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# SEÇÃO 2: CARREGAMENTO DOS DADOS (VERSÃO CORRIGIDA)\n",
    "# ==============================================================================\n",
    "print(\"\\nCarregando os datasets (train, test, stores, features)...\")\n",
    "try:\n",
    "    # Carregando os quatro arquivos CSV do dataset\n",
    "    df_train = pd.read_csv('train.csv')\n",
    "    df_test = pd.read_csv('test.csv')\n",
    "    df_stores = pd.read_csv('stores.csv')\n",
    "    df_features = pd.read_csv('features.csv')\n",
    "    print(\"Datasets carregados com sucesso.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Erro: Arquivo não encontrado. Verifique se os arquivos CSV estão na mesma pasta que o script. Detalhe: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ==============================================================================\n",
    "# SEÇÃO 3: MERGE E PRÉ-PROCESSAMENTO DOS DADOS\n",
    "# ==============================================================================\n",
    "print(\"\\nIniciando o pré-processamento e unificação dos dados...\")\n",
    "\n",
    "# --- Processando o DataFrame de TREINO ---\n",
    "# Juntando stores e features primeiro\n",
    "df_features_stores = pd.merge(df_features, df_stores, on='Store', how='left')\n",
    "# Agora juntando com o dataset de treino\n",
    "df_train_completo = pd.merge(df_train, df_features_stores, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
    "\n",
    "# --- Processando o DataFrame de TESTE (aplicando os mesmos passos) ---\n",
    "# Juntando com o dataset de teste\n",
    "df_test_completo = pd.merge(df_test, df_features_stores, on=['Store', 'Date', 'IsHoliday'], how='left')\n",
    "\n",
    "# Lidando com valores ausentes em ambos os DataFrames\n",
    "df_train_completo.fillna(0, inplace=True)\n",
    "df_test_completo.fillna(0, inplace=True)\n",
    "\n",
    "print(\"Merge e tratamento de valores nulos concluídos para ambos os datasets.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# SEÇÃO 4: ENGENHARIA DE ATRIBUTOS (FEATURE ENGINEERING)\n",
    "# ==============================================================================\n",
    "print(\"\\nCriando novas features para ambos os datasets...\")\n",
    "\n",
    "# Função para aplicar a engenharia de atributos em qualquer DataFrame\n",
    "def criar_features(df):\n",
    "    # Convertendo a coluna 'Date' para o formato de data\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    # Extraindo informações da data\n",
    "    df['Ano'] = df['Date'].dt.year\n",
    "    df['Mes'] = df['Date'].dt.month\n",
    "    df['Dia'] = df['Date'].dt.day\n",
    "    df['Semana_do_Ano'] = df['Date'].dt.isocalendar().week.astype(int)\n",
    "    # Convertendo 'IsHoliday' para 0 ou 1\n",
    "    df['IsHoliday'] = df['IsHoliday'].astype(int)\n",
    "    return df\n",
    "\n",
    "# Aplicando a função nos dois datasets\n",
    "df_train_final = criar_features(df_train_completo)\n",
    "df_test_final = criar_features(df_test_completo)\n",
    "\n",
    "# Usando One-Hot Encoding para a coluna 'Type'\n",
    "# Fazemos isso nos dois datasets juntos para garantir que ambos tenham as mesmas colunas\n",
    "df_full = pd.concat([df_train_final, df_test_final])\n",
    "df_full = pd.get_dummies(df_full, columns=['Type'], prefix='Tipo')\n",
    "\n",
    "# Separando de volta em treino e teste\n",
    "df_train_final = df_full[df_full['Weekly_Sales'].notna()]\n",
    "df_test_final = df_full[df_full['Weekly_Sales'].isna()]\n",
    "\n",
    "\n",
    "print(\"Novas features criadas com sucesso.\")\n",
    "print(\"Amostra do DataFrame de treino final:\")\n",
    "print(df_train_final.head())\n",
    "\n",
    "# ==============================================================================\n",
    "# SEÇÃO 5: CRIANDO UM CONJUNTO DE VALIDAÇÃO\n",
    "# ==============================================================================\n",
    "# Para avaliar nosso modelo, vamos separar os últimos meses do conjunto de TREINO\n",
    "# para usar como um conjunto de VALIDAÇÃO.\n",
    "data_corte_validacao = '2012-01-01'\n",
    "print(f\"\\nDividindo o dataset de treino em treino e validação (corte em {data_corte_validacao}).\")\n",
    "\n",
    "# Dados para treinar o modelo de fato\n",
    "train_set = df_train_final[df_train_final['Date'] < data_corte_validacao]\n",
    "# Dados para validar a performance do modelo\n",
    "validation_set = df_train_final[df_train_final['Date'] >= data_corte_validacao]\n",
    "\n",
    "# Definindo as features e o alvo\n",
    "target = 'Weekly_Sales'\n",
    "# Removemos o alvo e a coluna de data original das features\n",
    "features = [col for col in df_train_final.columns if col not in [target, 'Date']]\n",
    "\n",
    "X_train = train_set[features]\n",
    "y_train = train_set[target]\n",
    "\n",
    "X_val = validation_set[features]\n",
    "y_val = validation_set[target]\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {len(X_train)} linhas\")\n",
    "print(f\"Tamanho do conjunto de validação: {len(X_val)} linhas\")\n",
    "\n",
    "# ==============================================================================\n",
    "# SEÇÃO 6: TREINAMENTO DO MODELO RANDOM FOREST\n",
    "# ==============================================================================\n",
    "print(\"\\nIniciando o treinamento do modelo Random Forest...\")\n",
    "\n",
    "# Instanciando o modelo\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, min_samples_leaf=2)\n",
    "\n",
    "# Treinando o modelo com o conjunto de treino\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Modelo treinado com sucesso.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# SEÇÃO 7: PREVISÕES E AVALIAÇÃO DO MODELO NO CONJUNTO DE VALIDAÇÃO\n",
    "# ==============================================================================\n",
    "print(\"\\nRealizando previsões no conjunto de validação...\")\n",
    "\n",
    "# Usando o modelo treinado para prever no conjunto de validação\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "print(\"Avaliando a acurácia do modelo...\")\n",
    "\n",
    "# Calculando as métricas de erro\n",
    "mae = mean_absolute_error(y_val, predictions)\n",
    "mse = mean_squared_error(y_val, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"\\n--- MÉTRICAS DE AVALIAÇÃO (no conjunto de validação) ---\")\n",
    "print(f\"Erro Absoluto Médio (MAE): ${mae:,.2f}\")\n",
    "print(\"-> Em média, as previsões do modelo erraram em +/- este valor.\\n\")\n",
    "\n",
    "print(f\"Erro Quadrático Médio (MSE): {mse:,.2f}\")\n",
    "print(\"-> Métrica que penaliza mais os erros grandes.\\n\")\n",
    "\n",
    "print(f\"Raiz do Erro Quadrático Médio (RMSE): ${rmse:,.2f}\")\n",
    "print(\"-> Similar ao MAE, mas mais sensível a erros grandes.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
